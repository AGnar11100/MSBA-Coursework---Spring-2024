{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b54ba3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from mord import LogisticIT\n",
    "\n",
    "from dmba import classificationSummary, regressionSummary\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f99cd4",
   "metadata": {},
   "source": [
    "##### 1. Upload, explore, clean, and preprocess data for neural network modeling. (This part of the case\n",
    "will not be graded as all questions below have already been done in case study #1).\n",
    "\n",
    "a. Create a boston_df data frame by uploading the original data set into Python. Determine\n",
    "and present in this report the data frame dimensions, i.e., number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8eb0c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    boston_df = pd.read_csv('BostonHousing.csv')\n",
    "except:\n",
    "    print(\"BostonHousing.csv is not in the present working directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22fee058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the Boston Housing dataset is (506, 14) where there are 506 rows and 14 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The dimensions of the Boston Housing dataset is {boston_df.shape}\", f\"where there are {boston_df.shape[0]} rows and {boston_df.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122ade38",
   "metadata": {},
   "source": [
    "b. Display in Python the column titles. If some of them contain two (or more) words, convert\n",
    "them into one-word titles, and present the modified titles in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82457cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIME', 'ZONE', 'INDUST', 'CHAR_RIV', 'NIT_OXIDE', 'ROOMS', 'AGE',\n",
       "       'DISTANCE', 'RADIAL', 'TAX', 'ST_RATIO', 'LOW_STAT', 'MVALUE',\n",
       "       'C_MVALUE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.columns = boston_df.columns.str.replace(' ', '_')\n",
    "boston_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ec4ef1",
   "metadata": {},
   "source": [
    "c. Display in Python column data types. If some of them are listed as “object’, convert them\n",
    "into dummy variables, and provide in your report the modified list of column titles with\n",
    "dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "916f2162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIME        float64\n",
       "ZONE         float64\n",
       "INDUST       float64\n",
       "CHAR_RIV      object\n",
       "NIT_OXIDE    float64\n",
       "ROOMS        float64\n",
       "AGE          float64\n",
       "DISTANCE     float64\n",
       "RADIAL         int64\n",
       "TAX            int64\n",
       "ST_RATIO     float64\n",
       "LOW_STAT     float64\n",
       "MVALUE       float64\n",
       "C_MVALUE      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43eb028",
   "metadata": {},
   "outputs": [],
   "source": [
    "boston_df.CHAR_RIV = boston_df.CHAR_RIV.astype('category')\n",
    "boston_df.C_MVALUE = boston_df.C_MVALUE.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "688512ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIME', 'ZONE', 'INDUST', 'NIT_OXIDE', 'ROOMS', 'AGE', 'DISTANCE',\n",
       "       'RADIAL', 'TAX', 'ST_RATIO', 'LOW_STAT', 'MVALUE', 'CHAR_RIV_Y',\n",
       "       'C_MVALUE_Yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df = pd.get_dummies(boston_df, prefix_sep='_', \n",
    "                            drop_first=True)\n",
    "boston_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578e0c99",
   "metadata": {},
   "source": [
    "##### 2. Develop a neural network model for Boston Housing and use it for predictions.\n",
    "\n",
    "a. Develop in Python the outcome and predictor variables, partition the data set (70% for\n",
    "training and 30% for validation partitions), display in Python and present in your report\n",
    "the first five records of the training partition. Then, using the StandardScaler() function,\n",
    "develop the scaled predictors for training and validation partitions. Display in Python and\n",
    "provide in your report the first five records of the scaled training partition. Present a brief\n",
    "explanation of what the scaled values mean and how they are calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9959f671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRIME', 'ZONE', 'INDUST', 'NIT_OXIDE', 'ROOMS', 'AGE', 'DISTANCE',\n",
       "       'RADIAL', 'TAX', 'ST_RATIO', 'LOW_STAT', 'MVALUE', 'CHAR_RIV_Y',\n",
       "       'C_MVALUE_Yes'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97907d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = ['CRIME', 'ZONE', 'INDUST', 'NIT_OXIDE', 'ROOMS', 'AGE', 'DISTANCE',\n",
    "       'RADIAL', 'TAX', 'ST_RATIO', 'LOW_STAT', 'CHAR_RIV_Y',\n",
    "       'C_MVALUE_Yes']\n",
    "outcome = 'MVALUE'\n",
    "\n",
    "X = boston_df[predictors]\n",
    "y = boston_df[outcome]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46984cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89fe59c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIME</th>\n",
       "      <th>ZONE</th>\n",
       "      <th>INDUST</th>\n",
       "      <th>NIT_OXIDE</th>\n",
       "      <th>ROOMS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>RADIAL</th>\n",
       "      <th>TAX</th>\n",
       "      <th>ST_RATIO</th>\n",
       "      <th>LOW_STAT</th>\n",
       "      <th>CHAR_RIV_Y</th>\n",
       "      <th>C_MVALUE_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.62976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.949</td>\n",
       "      <td>61.8</td>\n",
       "      <td>4.7075</td>\n",
       "      <td>4</td>\n",
       "      <td>307</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.17171</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.453</td>\n",
       "      <td>5.966</td>\n",
       "      <td>93.4</td>\n",
       "      <td>6.8185</td>\n",
       "      <td>8</td>\n",
       "      <td>284</td>\n",
       "      <td>19.7</td>\n",
       "      <td>14.44</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>9.82349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.671</td>\n",
       "      <td>6.794</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.3580</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>20.2</td>\n",
       "      <td>21.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.02763</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.428</td>\n",
       "      <td>6.595</td>\n",
       "      <td>21.8</td>\n",
       "      <td>5.4011</td>\n",
       "      <td>3</td>\n",
       "      <td>252</td>\n",
       "      <td>18.3</td>\n",
       "      <td>4.32</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>4.55587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.718</td>\n",
       "      <td>3.561</td>\n",
       "      <td>87.9</td>\n",
       "      <td>1.6132</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>20.2</td>\n",
       "      <td>7.12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIME  ZONE  INDUST  NIT_OXIDE  ROOMS   AGE  DISTANCE  RADIAL  TAX  \\\n",
       "13   0.62976   0.0    8.14      0.538  5.949  61.8    4.7075       4  307   \n",
       "61   0.17171  25.0    5.13      0.453  5.966  93.4    6.8185       8  284   \n",
       "377  9.82349   0.0   18.10      0.671  6.794  98.8    1.3580      24  666   \n",
       "39   0.02763  75.0    2.95      0.428  6.595  21.8    5.4011       3  252   \n",
       "365  4.55587   0.0   18.10      0.718  3.561  87.9    1.6132      24  666   \n",
       "\n",
       "     ST_RATIO  LOW_STAT  CHAR_RIV_Y  C_MVALUE_Yes  \n",
       "13       21.0      8.26           0             0  \n",
       "61       19.7     14.44           0             0  \n",
       "377      20.2     21.24           0             0  \n",
       "39       18.3      4.32           0             1  \n",
       "365      20.2      7.12           0             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# present this \n",
    "train_X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d336c8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale here\n",
    "sc_X = StandardScaler()\n",
    "train_X_sc = sc_X.fit_transform(train_X)\n",
    "valid_X_sc = sc_X.transform(valid_X)\n",
    "\n",
    "train_X_sc_df = np.round(pd.DataFrame(train_X_sc), decimals=3)                            \n",
    "train_X_sc_df.columns=predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0df12b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIME</th>\n",
       "      <th>ZONE</th>\n",
       "      <th>INDUST</th>\n",
       "      <th>NIT_OXIDE</th>\n",
       "      <th>ROOMS</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>RADIAL</th>\n",
       "      <th>TAX</th>\n",
       "      <th>ST_RATIO</th>\n",
       "      <th>LOW_STAT</th>\n",
       "      <th>CHAR_RIV_Y</th>\n",
       "      <th>C_MVALUE_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.366</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>-0.462</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.251</td>\n",
       "      <td>0.412</td>\n",
       "      <td>-0.646</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>1.189</td>\n",
       "      <td>-0.647</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>-0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.420</td>\n",
       "      <td>0.580</td>\n",
       "      <td>-0.902</td>\n",
       "      <td>-0.868</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>0.868</td>\n",
       "      <td>1.401</td>\n",
       "      <td>-0.191</td>\n",
       "      <td>-0.736</td>\n",
       "      <td>0.582</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>-0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.714</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.782</td>\n",
       "      <td>1.060</td>\n",
       "      <td>-1.157</td>\n",
       "      <td>1.629</td>\n",
       "      <td>1.512</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.139</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>-0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.436</td>\n",
       "      <td>2.708</td>\n",
       "      <td>-1.220</td>\n",
       "      <td>-1.080</td>\n",
       "      <td>0.494</td>\n",
       "      <td>-1.668</td>\n",
       "      <td>0.737</td>\n",
       "      <td>-0.760</td>\n",
       "      <td>-0.924</td>\n",
       "      <td>-0.070</td>\n",
       "      <td>-1.189</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>2.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.095</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>0.992</td>\n",
       "      <td>1.381</td>\n",
       "      <td>-3.893</td>\n",
       "      <td>0.673</td>\n",
       "      <td>-1.037</td>\n",
       "      <td>1.629</td>\n",
       "      <td>1.512</td>\n",
       "      <td>0.816</td>\n",
       "      <td>-0.804</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>-0.452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRIME   ZONE  INDUST  NIT_OXIDE  ROOMS    AGE  DISTANCE  RADIAL    TAX  \\\n",
       "0 -0.366 -0.484  -0.462     -0.147 -0.440 -0.251     0.412  -0.646 -0.600   \n",
       "1 -0.420  0.580  -0.902     -0.868 -0.416  0.868     1.401  -0.191 -0.736   \n",
       "2  0.714 -0.484   0.992      0.982  0.782  1.060    -1.157   1.629  1.512   \n",
       "3 -0.436  2.708  -1.220     -1.080  0.494 -1.668     0.737  -0.760 -0.924   \n",
       "4  0.095 -0.484   0.992      1.381 -3.893  0.673    -1.037   1.629  1.512   \n",
       "\n",
       "   ST_RATIO  LOW_STAT  CHAR_RIV_Y  C_MVALUE_Yes  \n",
       "0     1.189    -0.647      -0.304        -0.452  \n",
       "1     0.582     0.203      -0.304        -0.452  \n",
       "2     0.816     1.139      -0.304        -0.452  \n",
       "3    -0.070    -1.189      -0.304         2.214  \n",
       "4     0.816    -0.804      -0.304        -0.452  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# present this\n",
    "train_X_sc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790a79ad",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Explanation of what the scaled values mean and how they are calculated:\n",
    "\n",
    "Standardization of a dataset is a common requirement for many machine learning estimators since they might behave \n",
    "badly if the individual features do not more or less look like standard normally distributed data. \n",
    "The calculation that is made when using the standard scaler is as follows:\n",
    "z = (x - u) / s\n",
    "where u is the mean of the training samples and s is the standard deviation of the training samples.\n",
    "\n",
    "For the training partition we can use the fit_transform function to first perform the calculation stated above, then transform\n",
    "the partition so that the values are adjusted to fit a standard normal distribution. Since the scaler is already fitted, the tranform\n",
    "function just needed to be applied to the validation partition to undergo the same transformation.  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fd7b8e",
   "metadata": {},
   "source": [
    "b. Train a neural network model using MLPRegressor() with the scaled training data set and\n",
    "the following parameters: hidden_layer_sizes=10, solver=’lbfgs’, max_iter=10000, and\n",
    "random_state=1. Identify and display in Python the final intercepts and network weights\n",
    "of this model. Provide these intercepts and weights in your report and briefly explain what\n",
    "the values of intercepts in the first and second arrays mean. Also, briefly explain what the\n",
    "values of weights in the first and second arrays mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "866da56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Intercepts for Boston Housing Neural Network Model\n",
      "[array([ 0.03419315, -5.17494472, -3.19741419,  0.09979904, -1.52105762,\n",
      "       -1.35938186, -0.98147659,  0.20502791,  3.90980501,  0.05306107]), array([1.89670365])]\n",
      "\n",
      "Network Weights for Boston Housing Neural Network Model\n",
      "[array([[ 6.78417419e-01,  1.40009172e+00, -2.90503954e-01,\n",
      "         7.00785971e-01, -2.33128946e+00, -1.88707724e-01,\n",
      "        -1.10882033e+00, -3.48212572e-01, -4.05340615e-02,\n",
      "         2.81750728e-01],\n",
      "       [ 9.13742181e-01,  1.17283170e-01,  4.63067759e-01,\n",
      "         1.60207856e+00, -2.70619848e+00, -4.00493501e-02,\n",
      "        -4.56463641e-01, -9.63440430e-01,  3.37150294e-01,\n",
      "         1.85719544e+00],\n",
      "       [ 1.15795214e+00,  8.58982703e-01, -1.15996602e-02,\n",
      "        -4.76552881e-01,  2.67668766e-01,  8.13217035e-01,\n",
      "        -4.95596540e-01, -2.31666290e-01,  1.33624317e-01,\n",
      "        -1.54542128e+00],\n",
      "       [ 1.32957065e+00,  6.32224008e-01, -5.34757482e-01,\n",
      "        -3.11797925e+00,  1.98344263e+00,  1.98515159e-01,\n",
      "         3.53150071e-01,  1.57389121e+00, -3.11587045e+00,\n",
      "         8.53350866e-01],\n",
      "       [ 2.59846306e+00,  7.65059220e-01, -3.42193107e-01,\n",
      "        -8.88413425e-01,  2.97602894e-01,  1.09954270e+00,\n",
      "        -5.67326502e-01, -3.47552978e-02, -2.18158702e-03,\n",
      "         5.73247359e-01],\n",
      "       [-1.02904031e+00, -1.39976705e-01, -8.34613188e-01,\n",
      "        -1.04880999e+00, -4.94132403e-01, -2.94284492e-01,\n",
      "         4.45657025e-01,  1.09623048e+00, -8.39853433e-01,\n",
      "        -7.52867827e-01],\n",
      "       [-1.43624123e+00, -3.98134531e-01, -7.63247169e-01,\n",
      "         1.69432537e-01,  2.76172744e-01,  1.75199651e-01,\n",
      "        -1.60496896e+00,  1.72223308e+00, -7.66136145e-01,\n",
      "         8.86732031e-01],\n",
      "       [ 5.16577863e-01, -1.41104072e+00, -3.68636450e-02,\n",
      "        -9.27011597e-01, -1.16521603e-01,  5.18275115e-01,\n",
      "         1.51939793e+00, -1.06601021e+00,  1.10589582e+00,\n",
      "        -1.97841803e+00],\n",
      "       [ 3.50368825e-01, -2.49796818e+00, -9.58338047e-01,\n",
      "         1.18243411e+00,  1.88740007e-01,  2.28376679e+00,\n",
      "         1.36159036e+00,  1.91341090e+00, -7.99699604e-01,\n",
      "         2.59782916e+00],\n",
      "       [ 2.87911289e-01, -5.67029528e-01, -8.23922769e-01,\n",
      "        -1.71974958e-01, -3.49289893e-01, -1.79011198e-01,\n",
      "         2.14643943e+00,  1.06856011e+00, -8.84082915e-01,\n",
      "         1.48873655e+00],\n",
      "       [-7.37997633e-01, -2.69402262e+00,  1.45608445e+00,\n",
      "        -3.18516362e-01,  2.19259387e-01,  3.36744109e-01,\n",
      "         8.57544062e-01, -1.00543762e+00, -3.56671373e-01,\n",
      "        -3.99033793e-01],\n",
      "       [-1.18412015e+00, -2.01945152e-01, -2.26204133e-01,\n",
      "        -2.28686545e-01, -1.20247666e+00, -7.17183945e-01,\n",
      "        -1.05780495e+00,  9.20547648e-01, -9.53629049e-02,\n",
      "        -6.57145473e-01],\n",
      "       [-8.53530575e-01, -1.32729949e-01,  2.19825046e+00,\n",
      "         1.78294870e-01, -1.45586826e-02, -1.85926303e+00,\n",
      "         1.72367387e+00,  3.31674658e+00, -1.74981202e+00,\n",
      "         2.44684662e-02]]), array([[ 1.40173896],\n",
      "       [ 4.93294787],\n",
      "       [ 3.70829147],\n",
      "       [-2.81677763],\n",
      "       [ 2.01379349],\n",
      "       [-2.580327  ],\n",
      "       [ 1.56837554],\n",
      "       [ 2.69568461],\n",
      "       [ 3.65371122],\n",
      "       [ 2.02015303]])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nBriefly explain what the values of intercepts in the first and second arrays mean: \\nThe final values of intercepts in the first array represent the coefficients for each of the hidden layers.  \\nThe final values of intercepts in the second array represent the coefficients of the output node. \\n\\nsee slide 17 of the neural net slides\\n\\nBriefly explain what the values of weights in the first and second arrays mean:\\nThe values of weights in the first array represents the weights that point from each of the input nodes (13 features = 13 lists of weights)\\nto the hidden nodes. \\nThe values in the second array represents the weights that point to the output node.\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_reg = MLPRegressor(hidden_layer_sizes=(10), \n",
    "                solver='lbfgs', max_iter=10000, random_state=1)\n",
    "boston_reg.fit(train_X_sc, train_y)\n",
    "\n",
    "# PRESENT IN REPORT\n",
    "# Display network structure with the final values of \n",
    "# intercepts (Theta) and weights (W).\n",
    "print('Final Intercepts for Boston Housing Neural Network Model')\n",
    "print(boston_reg.intercepts_)\n",
    "\n",
    "print()\n",
    "print('Network Weights for Boston Housing Neural Network Model')\n",
    "print(boston_reg.coefs_)\n",
    "\n",
    "\"\"\"\n",
    "Briefly explain what the values of intercepts in the first and second arrays mean: \n",
    "The final values of intercepts in the first array represent the coefficients for each of the hidden layers.  \n",
    "The final values of intercepts in the second array represent the coefficients of the output node. \n",
    "\n",
    "see slide 17 of the neural net slides\n",
    "\n",
    "Briefly explain what the values of weights in the first and second arrays mean:\n",
    "The values of weights in the first array represents the weights that point from each of the input nodes (13 features = 13 lists of weights)\n",
    "to the hidden nodes. \n",
    "The values in the second array represents the weights that point to the output node.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234fb338",
   "metadata": {},
   "source": [
    "c. Using the developed neural network model, make in Python predictions for the outcome\n",
    "variable (MVALUE) using the scaled validation predictors. Based on these predictions,\n",
    "develop and display in Python a table for the first five validation records that contain\n",
    "actual and predicted median prices (MVALUE), and their residuals. Present this table in\n",
    "your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17b89d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for House Price for Validation Partition\n",
      "     Actual  Prediction  Residual\n",
      "307    28.2       29.63     -1.43\n",
      "343    23.9       25.81     -1.91\n",
      "47     16.6       20.65     -4.05\n",
      "67     22.0       20.63      1.37\n",
      "362    20.8       24.47     -3.67\n"
     ]
    }
   ],
   "source": [
    "# Make 'MVALUE' predictions for validation set using Boston housing \n",
    "# neural network model. \n",
    "\n",
    "# Use boston_reg model to predict 'MVALUE' outcome\n",
    "# for validation set.\n",
    "mvalue_pred = np.round(boston_reg.predict(valid_X_sc), decimals=2)\n",
    "\n",
    "# Create data frame to display prediction results for\n",
    "# validation set. \n",
    "mvalue_pred_result = pd.DataFrame({'Actual': valid_y, \n",
    "                'Prediction': mvalue_pred, 'Residual': valid_y-mvalue_pred})\n",
    "\n",
    "print('Predictions for House Price for Validation Partition')\n",
    "print(mvalue_pred_result.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29575cce",
   "metadata": {},
   "source": [
    "d. Identify and display in Python the common accuracy measures for training and validation\n",
    "partitions. Provide and compare these accuracy measures in your report based on RMSE\n",
    "and MAPE, and assess the possibility of overfitting. Would you recommend applying this\n",
    "neural network model for predictions? Briefly explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1be47357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Measures for Training Partition for Neural Network\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -0.0033\n",
      "       Root Mean Squared Error (RMSE) : 1.5851\n",
      "            Mean Absolute Error (MAE) : 1.1342\n",
      "          Mean Percentage Error (MPE) : -0.9031\n",
      "Mean Absolute Percentage Error (MAPE) : 6.1132\n",
      "\n",
      "Accuracy Measures for Validation Partition for Neural Network\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -0.5680\n",
      "       Root Mean Squared Error (RMSE) : 3.9407\n",
      "            Mean Absolute Error (MAE) : 2.7470\n",
      "          Mean Percentage Error (MPE) : -5.4903\n",
      "Mean Absolute Percentage Error (MAPE) : 14.5074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTODO\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural network model accuracy measures for training and\n",
    "# validation partitions. \n",
    "\n",
    "# Identify and display neural network model accuracy measures \n",
    "# for training partition.\n",
    "print('Accuracy Measures for Training Partition for Neural Network')\n",
    "regressionSummary(train_y, boston_reg.predict(train_X_sc))\n",
    "\n",
    "# Identify and display neural network accuracy measures \n",
    "# for validation partition.\n",
    "print()\n",
    "print('Accuracy Measures for Validation Partition for Neural Network')\n",
    "regressionSummary(valid_y, boston_reg.predict(valid_X_sc))\n",
    "\n",
    "\"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17350fc1",
   "metadata": {},
   "source": [
    "##### 3. Develop an improved neural network model with grid search.\n",
    "\n",
    "a. Use GridSearchCV() function to identify the best number of nodes for the hidden layer in\n",
    "the Boston Housing neural network model. For that, consider the hidden_layer_sizes\n",
    "parameter in a range from 2 to 20. Provide in your report the best score and best\n",
    "parameter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7fb3a994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score:0.8877\n",
      "Best parameter:  {'hidden_layer_sizes': 2}\n"
     ]
    }
   ],
   "source": [
    "# Identify grid search parameters. \n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': list(range(2, 20))\n",
    "}\n",
    "\n",
    "# Utilize GridSearchCV() to identify the best number \n",
    "# of nodes in the hidden layer. \n",
    "gridSearch = GridSearchCV(MLPRegressor(solver='lbfgs', max_iter=10000, random_state=1), \n",
    "                          param_grid, cv=5, n_jobs=-1, return_train_score=True)\n",
    "gridSearch.fit(train_X_sc, train_y)\n",
    "\n",
    "# Display the best score and best parament value.\n",
    "print(f'Best score:{gridSearch.best_score_:.4f}')\n",
    "print('Best parameter: ', gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac86b9",
   "metadata": {},
   "source": [
    "b. Train an improved neural network model using MLPRegressor() with the scaled training\n",
    "data set and the best identified value of the parameter from the previous question. The\n",
    "rest of the parameters remain the same as in model developed in 2b. Present in your\n",
    "report the final intercepts and network weights of the improved neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65008c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Intercepts for Boston Housing Neural Network Model\n",
      "[array([-5.8049252 ,  9.24593197]), array([6.40051439])]\n",
      "\n",
      "Network Weights for Boston Housing Neural Network Model\n",
      "[array([[-0.30389718, -1.13481572],\n",
      "       [-0.82423068,  0.01522733],\n",
      "       [ 3.41753368, -0.19618274],\n",
      "       [-0.8772186 , -0.35023142],\n",
      "       [-1.38317186,  2.43543214],\n",
      "       [ 0.02280384, -0.99890554],\n",
      "       [-0.33525388, -1.02588688],\n",
      "       [ 3.41626164, -0.42845199],\n",
      "       [ 1.70241347, -1.51513226],\n",
      "       [-1.32750925, -0.71321435],\n",
      "       [-1.27314847, -0.4747823 ],\n",
      "       [ 0.23793571,  0.12117713],\n",
      "       [ 3.18966496,  1.48465918]]), array([[2.28575643],\n",
      "       [1.50263471]])]\n"
     ]
    }
   ],
   "source": [
    "boston_reg_opt_layers = MLPRegressor(hidden_layer_sizes=(2), \n",
    "                solver='lbfgs', max_iter=10000, random_state=1)\n",
    "boston_reg_opt_layers.fit(train_X_sc, train_y)\n",
    "\n",
    "# PRESENT IN REPORT\n",
    "# Display network structure with the final values of \n",
    "# intercepts (Theta) and weights (W).\n",
    "print('Final Intercepts for Boston Housing Neural Network Model')\n",
    "print(boston_reg_opt_layers.intercepts_)\n",
    "\n",
    "print()\n",
    "print('Network Weights for Boston Housing Neural Network Model')\n",
    "print(boston_reg_opt_layers.coefs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ac1fc4",
   "metadata": {},
   "source": [
    "c. Identify and display in Python the common accuracy measures for the training and\n",
    "validation partitions with the improved neural network model. Provide and compare the\n",
    "these accuracy measures, specifically RMSE and MAPE, in your report and assess the\n",
    "possibility of overfitting. Would you recommend applying this neural network model for\n",
    "predictions? Briefly explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55ac38a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Measures for Training Partition for Neural Network\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : -0.0001\n",
      "       Root Mean Squared Error (RMSE) : 2.6987\n",
      "            Mean Absolute Error (MAE) : 2.0674\n",
      "          Mean Percentage Error (MPE) : -1.8526\n",
      "Mean Absolute Percentage Error (MAPE) : 10.6337\n",
      "\n",
      "Accuracy Measures for Validation Partition for Neural Network\n",
      "\n",
      "Regression statistics\n",
      "\n",
      "                      Mean Error (ME) : 0.1367\n",
      "       Root Mean Squared Error (RMSE) : 3.0185\n",
      "            Mean Absolute Error (MAE) : 2.2846\n",
      "          Mean Percentage Error (MPE) : -2.7484\n",
      "Mean Absolute Percentage Error (MAPE) : 12.1011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nTODO\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural network model accuracy measures for training and\n",
    "# validation partitions. \n",
    "\n",
    "# Identify and display neural network model accuracy measures \n",
    "# for training partition.\n",
    "print('Accuracy Measures for Training Partition for Neural Network')\n",
    "regressionSummary(train_y, boston_reg_opt_layers.predict(train_X_sc))\n",
    "\n",
    "# Identify and display neural network accuracy measures \n",
    "# for validation partition.\n",
    "print()\n",
    "print('Accuracy Measures for Validation Partition for Neural Network')\n",
    "regressionSummary(valid_y, boston_reg_opt_layers.predict(valid_X_sc))\n",
    "\n",
    "\"\"\"\n",
    "TODO\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17b33e6",
   "metadata": {},
   "source": [
    "d. Present and compare the accuracy measures for the validation partition from the\n",
    "Backward Elimination model for the multiple linear regression in case study #1 and the\n",
    "validation partition for the improved neural network model in this case. Which of the\n",
    "models would you recommend for predictions? Briefly explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1082079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# refer to case study #1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
