{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and Regression Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dmba\n",
    "# !pip install graphviz\n",
    "# !conda install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep +'c:/users/naran/Anaconda3/envs/keras/Library/bin/graphviz/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import graphviz\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from dmba import plotDecisionTree, classificationSummary, regressionSummary\n",
    "\n",
    "%matplotlib inline   \n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riding Mowers: first split, second split, and full split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Income  Lot_Size Ownership\n",
      "0     60.0      18.4     Owner\n",
      "1     85.5      16.8     Owner\n",
      "2     64.8      21.6     Owner\n",
      "3     61.5      20.8     Owner\n",
      "4     87.0      23.6     Owner\n",
      "5    110.1      19.2     Owner\n",
      "6    108.0      17.6     Owner\n",
      "7     82.8      22.4     Owner\n",
      "8     69.0      20.0     Owner\n",
      "9     93.0      20.8     Owner\n",
      "10    51.0      22.0     Owner\n",
      "11    81.0      20.0     Owner\n",
      "12    75.0      19.6  Nonowner\n",
      "13    52.8      20.8  Nonowner\n",
      "14    64.8      17.2  Nonowner\n",
      "15    43.2      20.4  Nonowner\n",
      "16    84.0      17.6  Nonowner\n",
      "17    49.2      17.6  Nonowner\n",
      "18    59.4      16.0  Nonowner\n",
      "19    66.0      18.4  Nonowner\n",
      "20    47.4      16.4  Nonowner\n",
      "21    33.0      18.8  Nonowner\n",
      "22    51.0      14.0  Nonowner\n",
      "23    63.0      14.8  Nonowner\n"
     ]
    }
   ],
   "source": [
    "# Create data frame for Riding Mowers data set. \n",
    "mower_df = pd.read_csv('RidingMowers.csv')\n",
    "\n",
    "# Show the Riding Mower data frame.\n",
    "print(mower_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: Nonowner, Owner\n",
      "\n",
      "Classification Tree after First Split\n"
     ]
    },
    {
     "ename": "ExecutableNotFound",
     "evalue": "failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\graphviz\\backend\\execute.py:78\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m         proc \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun(cmd, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\subprocess.py:548\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    546\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClassification Tree after First Split\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m plotDecisionTree(classTree, feature_names\u001b[38;5;241m=\u001b[39mmower_df\u001b[38;5;241m.\u001b[39mcolumns[:\u001b[38;5;241m2\u001b[39m], class_names\u001b[38;5;241m=\u001b[39mclassTree\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\dmba\\graphs.py:117\u001b[0m, in \u001b[0;36mplotDecisionTree\u001b[1;34m(decisionTree, feature_names, class_names, impurity, label, max_depth, rotate, pdfFile)\u001b[0m\n\u001b[0;32m    115\u001b[0m     graph\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdot\u001b[39m\u001b[38;5;124m'\u001b[39m, directory\u001b[38;5;241m=\u001b[39mtempdir, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m'\u001b[39m, outfile\u001b[38;5;241m=\u001b[39mpdfFile)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hasImage:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Image(graph\u001b[38;5;241m.\u001b[39mrender(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdot\u001b[39m\u001b[38;5;124m'\u001b[39m, directory\u001b[38;5;241m=\u001b[39mtempdir, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\graphviz\\rendering.py:122\u001b[0m, in \u001b[0;36mRender.render\u001b[1;34m(self, filename, directory, view, cleanup, format, renderer, formatter, neato_no_op, quiet, quiet_view, outfile, engine, raise_if_result_exists, overwrite_source)\u001b[0m\n\u001b[0;32m    118\u001b[0m filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(filename, directory\u001b[38;5;241m=\u001b[39mdirectory, skip_existing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    120\u001b[0m args\u001b[38;5;241m.\u001b[39mappend(filepath)\n\u001b[1;32m--> 122\u001b[0m rendered \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_render(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cleanup:\n\u001b[0;32m    125\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdelete \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m, filepath)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\graphviz\\_tools.py:171\u001b[0m, in \u001b[0;36mdeprecate_positional_args.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     wanted \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    163\u001b[0m                        \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m deprecated\u001b[38;5;241m.\u001b[39mitems())\n\u001b[0;32m    164\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe signature of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m will be reduced\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    165\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_number\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m positional args\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    166\u001b[0m                   \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(supported)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: pass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwanted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    167\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m as keyword arg(s)\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    168\u001b[0m                   stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    169\u001b[0m                   category\u001b[38;5;241m=\u001b[39mcategory)\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\graphviz\\backend\\rendering.py:326\u001b[0m, in \u001b[0;36mrender\u001b[1;34m(engine, format, filepath, renderer, formatter, neato_no_op, quiet, outfile, raise_if_result_exists, overwrite_filepath)\u001b[0m\n\u001b[0;32m    322\u001b[0m cmd \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m filepath \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwork around pytype false alarm\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 326\u001b[0m execute\u001b[38;5;241m.\u001b[39mrun_check(cmd,\n\u001b[0;32m    327\u001b[0m                   cwd\u001b[38;5;241m=\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;28;01mif\u001b[39;00m filepath\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mparts \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    328\u001b[0m                   quiet\u001b[38;5;241m=\u001b[39mquiet,\n\u001b[0;32m    329\u001b[0m                   capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mfspath(outfile)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\graphviz\\backend\\execute.py:81\u001b[0m, in \u001b[0;36mrun_check\u001b[1;34m(cmd, input_lines, encoding, quiet, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[1;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ExecutableNotFound(cmd) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m quiet \u001b[38;5;129;01mand\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mstderr:\n",
      "\u001b[1;31mExecutableNotFound\u001b[0m: failed to execute WindowsPath('dot'), make sure the Graphviz executables are on your systems' PATH"
     ]
    }
   ],
   "source": [
    "# Apply DecisionTreeClassifier() function to create classification tree.\n",
    "# Use max_depth to control tree size: \n",
    "        # for the first split: max_depth=1;\n",
    "        # for the two splits:  max_depth=2;\n",
    "        # for full tree: max_depth=None (don't use it). \n",
    "# Parameter random_state controls randomness of the estimator,\n",
    "# for random_state=0, the integer value of 0 is a seed value\n",
    "# to control random choices in the function.\n",
    "\n",
    "# Create classification tree for the first split (max_depth=1)\n",
    "classTree = DecisionTreeClassifier(random_state=0, max_depth=1)\n",
    "\n",
    "# Fit Riding Mower data frame (Income and Lot_Size) into the tree. \n",
    "# Column 'Ownership' as outcome is not used for the fitting algorithm. \n",
    "classTree.fit(mower_df.drop(columns=['Ownership']), mower_df['Ownership'])\n",
    "\n",
    "# Display classes used in the classification tree: 'Nonowner' and 'Owner'. \n",
    "print(\"Classes: {}\".format(', '.join(classTree.classes_)))\n",
    "\n",
    "# Use plotDecisionTree() function to visualize the classfication tree.\n",
    "# The order of the 'value' in the boxes is the same as 'classTree.classes_',\n",
    "# i.e., the first number is 'Nonowners' and the second number 'Owners'.\n",
    "print()\n",
    "print('Classification Tree after First Split')\n",
    "plotDecisionTree(classTree, feature_names=mower_df.columns[:2], class_names=classTree.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create classification tree for the second split (max_depth=2).\n",
    "classTree = DecisionTreeClassifier(random_state=0, max_depth=2)\n",
    "\n",
    "# Fit Riding Mower data frame (Income and Lot_Size) into the tree. \n",
    "# Column 'Ownership' as outcome is not used for the fitting algorithm. \n",
    "classTree.fit(mower_df.drop(columns=['Ownership']), mower_df['Ownership'])\n",
    "\n",
    "# Display classes used in the classification tree: 'Nonowner' and 'Owner'.\n",
    "print(\"Classes: {}\".format(', '.join(classTree.classes_)))\n",
    "\n",
    "# Use plotDecisionTree() function to visualize the classfication tree.\n",
    "# The order of the 'value' in the boxes is the same as 'classTree.classes_',\n",
    "# i.e., the first number is 'Nonowners' and the second number 'Owners'.\n",
    "print()\n",
    "print('Classification Tree after Second Split')\n",
    "plotDecisionTree(classTree, feature_names=mower_df.columns[:2], class_names=classTree.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DecisionTreeClassifier() function to create full classification tree.\n",
    "# Don't use max_depth for growing full tree. \n",
    "classTree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Fit Riding Mower data frame (Income and Lot_Size) into the tree. \n",
    "# Column 'Ownership' is not used for the fitting algorithm. \n",
    "classTree.fit(mower_df.drop(columns=['Ownership']), mower_df['Ownership'])\n",
    "\n",
    "# Display classes used in the classification tree: 'Nonowner' and 'Owner'.\n",
    "print(\"Classes: {}\".format(', '.join(classTree.classes_)))\n",
    "\n",
    "# Use plotDecisionTree() function to visualize the classfication tree.\n",
    "# The order of the 'value' in the boxes is the same as 'classTree.classes_',\n",
    "# i.e., the first number is 'Nonowners' and the second number 'Owners'.\n",
    "print()\n",
    "print('Full Classification Tree after All Splits')\n",
    "plotDecisionTree(classTree, feature_names=mower_df.columns[:2], class_names=classTree.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riding Movers: apply confusion matrix and make classifications for new data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Riding Movers, create data frame with \n",
    "# classifiers (predictors), 'Income' and 'Lot_Size'.\n",
    "mower_df_X = mower_df.drop(columns=['Ownership'])\n",
    "\n",
    "# Create data frame with output variables, 'Owenership'.\n",
    "mower_df_Y = mower_df['Ownership']\n",
    "\n",
    "# Use the classificationSummary() function to create\n",
    "# a confusion matrix for the full classification tree.\n",
    "classificationSummary(mower_df_Y, classTree.predict(mower_df_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make Riding Mowers classification for new data set.\n",
    "\n",
    "# Develop data frame with 2 new records. \n",
    "# Notice that the 'Ownership' outcome variable\n",
    "# is not present in these records.\n",
    "new_data_mowers = pd.DataFrame({\n",
    "            'Income': [65, 48],\n",
    "            'Lot_Size': [20, 20.5],\n",
    "})\n",
    "\n",
    "# Make classifications for new data. \n",
    "pred_mowers = classTree.predict(new_data_mowers)\n",
    "\n",
    "# Display new data and classifications based on \n",
    "# new data.\n",
    "print('New Riding Mowers Data and Classifications for New Data')\n",
    "print(new_data_mowers)\n",
    "print('Classifications: ', pred_mowers)\n",
    "\n",
    "# Another way to display new data and classifications \n",
    "# for new data.\n",
    "pred_result = pd.DataFrame({\n",
    "            'Income': [65, 48],\n",
    "            'Lot_Size': [20, 20.5],\n",
    "            'Classification': pred_mowers,\n",
    "})\n",
    "print()\n",
    "print('New Riding Mowers Data and Classifications for New Data')\n",
    "print(pred_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Bank personal loan: grow full classification tree and develop confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame for Universal Bank data set and show\n",
    "# the first 10 records.\n",
    "bank_df = pd.read_csv('UniversalBank.csv')\n",
    "print(bank_df.head(10))\n",
    "\n",
    "# Drop (remove)'ID' and 'ZIP Code' variables which are\n",
    "# not relevant for model building.\n",
    "bank_df = bank_df.drop(columns=['ID', 'ZIP Code'])\n",
    "\n",
    "# Develop predictors X and output variable Y for the data set.\n",
    "X = bank_df.drop(columns=['Personal Loan'])\n",
    "y = bank_df['Personal Loan']\n",
    "\n",
    "# Develop training (60%) and validation(40% or 0.4) partitions for\n",
    "# UniversalBank data frame.\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grow full classification tree using training partition.\n",
    "fullClassTree = DecisionTreeClassifier(random_state=1)\n",
    "fullClassTree.fit(train_X, train_y)\n",
    "\n",
    "# Using plotDecisionTree() to visualize the full tree.\n",
    "plotDecisionTree(fullClassTree, feature_names=train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indetify and display number of nodes in the tree.\n",
    "tree_nodes = fullClassTree.tree_.node_count\n",
    "print('Number of nodes:', tree_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Confusion matrices for full classification tree. \n",
    "\n",
    "# Identify  and display confusion matrix for training partition. \n",
    "print('Training Partition')\n",
    "classificationSummary(train_y, fullClassTree.predict(train_X))\n",
    "\n",
    "# Identify  and display confusion matrix for validation partition. \n",
    "print()\n",
    "print('Validation Partition')\n",
    "classificationSummary(valid_y, fullClassTree.predict(valid_X))\n",
    "\n",
    "# Accuracy =(1790 + 168)/2000 = 0.9790 = 97.90%\n",
    "# Misclissification = (25+17)/2000 = 0.021 = 2.1% = 1- Accuracy = 1-0.979 = 0.021 = 2.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five-fold cross-validation for Universal Bank classification tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Five-fold cross-validation of the full decision tree classifier.\n",
    "# Develop full classification tree.  \n",
    "treeClassifier = DecisionTreeClassifier()\n",
    "\n",
    "# Use cross_val_score() function to identify performance \n",
    "# accuracy for 5 folds (cv=5) of cross-validation partitioning.\n",
    "scores = cross_val_score(treeClassifier, train_X, train_y, cv=5)\n",
    "\n",
    "# Display performance accuracy scores for each fold partition.\n",
    "# Use three decimals (.3f) for each accuracy score using the \n",
    "# acc (accumulator) parameter. \n",
    "print('Performance Accuracy of 5-Fold Cross-Validation')\n",
    "print('Accuracy scores of each fold: ', [f'{acc:.3f}' for acc in scores])\n",
    "\n",
    "# Indetify and display two standard deviation confidence interval for \n",
    "# population mean scores.\n",
    "print()\n",
    "print('Two Standard Deviation (95%) Confidence Interval for Mean Accuracy')\n",
    "print(f'Accuracy: {scores.mean():.3f} (+/- {scores.std() * 2:.3f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smaller classification tree using DecisionTreeClassifier() control parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a smaller classification tree for training partition\n",
    "# using DecisionTreeClassifier() function control parameters:\n",
    "#  - Maximum Tree depth (number of splits) = 30;\n",
    "#  - Minimum impurity decrease per split = 0.01 \n",
    "#  - Minimum number of sample records in a node for splitting = 20.   \n",
    "smallClassTree = DecisionTreeClassifier(max_depth=30, \n",
    "        min_impurity_decrease=0.01, min_samples_split=20)\n",
    "smallClassTree.fit(train_X, train_y)\n",
    "\n",
    "# Display classification tree for training partition.\n",
    "print('Small Classification Tree with Control Parameters')\n",
    "plotDecisionTree(smallClassTree, feature_names=train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Confusion matrices for smaller classification tree. \n",
    "\n",
    "# Identify  and display confusion matrix for training partition. \n",
    "print('Training Partition for Smaller Tree')\n",
    "classificationSummary(train_y, smallClassTree.predict(train_X))\n",
    "\n",
    "# Identify  and display confusion matrix for validation partition. \n",
    "print()\n",
    "print('Validation Partition for Smaller Tree')\n",
    "classificationSummary(valid_y, smallClassTree.predict(valid_X))\n",
    "\n",
    "# Miscalssfication for validation partition = 1 - 0.977 = 0.023 = 2.3% \n",
    "# Misclassification = (43 + 3)/2000 = 0.023 = 2.3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make classification for new data using smaller classfication tree. \n",
    "\n",
    "# Develop dataframe with 3 new records. Notice that the \n",
    "# 'Personal Loan' outcome variable is not present in these records. \n",
    "# New data is used for 'Income', 'Family', and 'Education', the 3\n",
    "# preditors used in smaller classification tree. \n",
    "new_data_small = pd.DataFrame({\n",
    "            'Age': [0,0,0],  \n",
    "            'Experience': [0,0,0],\n",
    "            'Income': [115, 122, 84],\n",
    "            'Family': [1, 4, 2],  \n",
    "            'CCAvg': [0, 0, 0],\n",
    "            'Education': [1, 3, 2],\n",
    "            'Mortgage': [0,0,0],\n",
    "            'Securities Account': [0, 0, 0],  \n",
    "            'CD Account': [0, 0, 0],  \n",
    "            'Online': [0, 0, 0],  \n",
    "            'CreditCard': [0, 0, 0],\n",
    "})\n",
    "\n",
    "# Make classifications for new data. \n",
    "pred_small_tree = smallClassTree.predict(new_data_small)\n",
    "\n",
    "# Make classifications for new Universal Bank data.\n",
    "pred_small_result = pd.DataFrame({\n",
    "            'Income': [115, 122, 84],\n",
    "            'Family': [1, 4, 2],\n",
    "            'Education': [1, 3, 2],\n",
    "            'Classification': pred_small_tree,\n",
    "})\n",
    "\n",
    "print()\n",
    "print('Classifications for Personal Loan')\n",
    "print(pred_small_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search for Universal Bank classification tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with initial guess for parameters.\n",
    "param_grid = {\n",
    "    'max_depth': [10, 20, 30, 40],  \n",
    "    'min_impurity_decrease': [0, 0.0005, 0.001, 0.005, 0.01], \n",
    "    'min_samples_split': [20, 40, 60, 80, 100],\n",
    "}\n",
    "\n",
    "# Apply GridSearchCV() fucntion for various combinations of\n",
    "# DecisionTreeClassifier() initial parameters. cv=5 means that\n",
    "# 5-fold cross-validation is used in this case, and n_jobs=-1 \n",
    "# means that the availalbe computer memory (CPU) will be \n",
    "# used to make calculations faster. \n",
    "gridSearch_init = GridSearchCV(DecisionTreeClassifier(), \n",
    "                   param_grid, cv=5, n_jobs=-1)\n",
    "gridSearch_init.fit(train_X, train_y)\n",
    "\n",
    "# Display best initial paramenters of classification tree. \n",
    "print(f'Initial score:{gridSearch_init.best_score_:.4f}')\n",
    "print('Initial parameters: ', gridSearch_init.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve grid search parameters by adapting grid based \n",
    "# on results from initial grid search parameters.\n",
    "param_grid = {\n",
    "    'max_depth': list(range(2, 20)),  \n",
    "    'min_impurity_decrease': [0, 0.0005, 0.001], \n",
    "    'min_samples_split': list(range(10, 30)),\n",
    "}\n",
    "\n",
    "# Apply GridSearchCV() fucntion for various combinations of\n",
    "# DecisionTreeClassifier() improved parameters. \n",
    "gridSearch = GridSearchCV(DecisionTreeClassifier(), \n",
    "                param_grid, cv=5, n_jobs=-1)\n",
    "gridSearch.fit(train_X, train_y)\n",
    "\n",
    "# Display best improved paramenters of classification tree. \n",
    "print()\n",
    "print(f'Improved score:{gridSearch.best_score_:.4f}')\n",
    "print('Improved parameters: ', gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create classification tree based on the improved parameters.\n",
    "bestClassTree = gridSearch.best_estimator_\n",
    "\n",
    "# Display classification tree based on improved parameters.\n",
    "print('Best Classification Tree with Grid Search')\n",
    "plotDecisionTree(bestClassTree, feature_names=train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indetify and display number of nodes in the tree\n",
    "# based on grid search.\n",
    "tree_nodes_grid = bestClassTree.tree_.node_count\n",
    "print('Number of nodes:', tree_nodes_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for grid search classification tree. \n",
    "\n",
    "# Identify and display confusion matrix for training partition. \n",
    "print('Training Partition')\n",
    "classificationSummary(train_y, bestClassTree.predict(train_X))\n",
    "\n",
    "# Identify and display confusion matrix for validation partition. \n",
    "print()\n",
    "print('Validation Partition')\n",
    "classificationSummary(valid_y, bestClassTree.predict(valid_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop regression tree for Toyota Corolla data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create data frame for Toyota Corolla data set with 1000 top records.\n",
    "ToyotaCorolla_df = pd.read_csv('ToyotaCorolla.csv').iloc[:1000,:]\n",
    "\n",
    "# Display column names of ToyotaCorolla data frame.\n",
    "print(ToyotaCorolla_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names, identify predictors and outcome, and data partitioning.\n",
    "\n",
    "# Change some column names to shorter names. \n",
    "ToyotaCorolla_df = ToyotaCorolla_df.rename(columns={'Age_08_04': 'Age', \n",
    "                   'Quarterly_Tax': 'Tax', 'Met_Color': 'Metalic',\n",
    "                   'Fuel_Type': 'Fuel'})\n",
    "\n",
    "# Identify predictors and outcome for regression tree. \n",
    "predictors = ['Age', 'KM', 'Fuel', 'HP', 'Metalic', 'Automatic', 'CC', \n",
    "              'Doors', 'Tax', 'Weight']\n",
    "outcome = 'Price'\n",
    "\n",
    "# Name predictors and outcome data frames as X and y, respectively. \n",
    "# Convert, if necessary, categorical variables to dummy variables. \n",
    "X = pd.get_dummies(ToyotaCorolla_df[predictors], drop_first=True)\n",
    "y = ToyotaCorolla_df[outcome]\n",
    "\n",
    "# Create data partition with training set, 60%(0.6), and \n",
    "# validation set 40%(0.4) of the ToyotaCorolla data set.\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search to find optimized regression tree.\n",
    "\n",
    "# Start with an initial guess for parameters.\n",
    "param_grid = {\n",
    "    'max_depth': [5, 10, 15, 20, 25], \n",
    "    'min_impurity_decrease': [0, 0.001, 0.005, 0.01], \n",
    "    'min_samples_split': [10, 20, 30, 40, 50],}\n",
    "\n",
    "# Apply GridSearchCV() fucntion for various combinations of\n",
    "# DecisionTreeRegressor() initial parameters. \n",
    "gridSearch = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=5, n_jobs=-1)\n",
    "gridSearch.fit(train_X, train_y)\n",
    "\n",
    "# Display best initial paramenters of regression tree. \n",
    "print(f'Initial score:{gridSearch.best_score_:.4f}')\n",
    "print('Initial parameters: ', gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improve grid search parameters by adapting grid based \n",
    "# on results from initial grid search parameters.\n",
    "param_grid = {\n",
    "    'max_depth': list(range(2, 10)), \n",
    "    'min_impurity_decrease': [0, 0.001, 0.002, 0.003, \n",
    "                   0.004, 0.005], \n",
    "    'min_samples_split': list(range(10, 30)), \n",
    "}\n",
    "\n",
    "# Apply GridSearchCV() fucntion for various combinations of\n",
    "# DecisionTreeRegressor() new parameters. \n",
    "gridSearch = GridSearchCV(DecisionTreeRegressor(), param_grid, cv=5, n_jobs=-1)\n",
    "gridSearch.fit(train_X, train_y)\n",
    "\n",
    "# Display best improved paramenters of regression tree. \n",
    "print()\n",
    "print(f'Improved score:{gridSearch.best_score_:.4f}')\n",
    "print('Improved parameters: ', gridSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regression tree based on the improved parameters. \n",
    "bestRegTree = gridSearch.best_estimator_\n",
    "\n",
    "# Display regression tree bestRegTree based on the best \n",
    "# parameters from grid search.\n",
    "plotDecisionTree(bestRegTree, feature_names=train_X.columns, rotate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indetify and display number of nodes in the regression tree.\n",
    "tree_nodes = bestRegTree.tree_.node_count\n",
    "print('Number of nodes:', tree_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Regression tree accuracy measures for training and\n",
    "# validation partitions. \n",
    "\n",
    "# Identify and display regression tree accuracy measures \n",
    "# for training partition.\n",
    "print('Accuracy Measures for Training Partition for Regression Tree')\n",
    "regressionSummary(train_y, bestRegTree.predict(train_X))\n",
    "\n",
    "# Identify and display regression tree accuracy measures \n",
    "# for validation partition.\n",
    "print()\n",
    "print('Accuracy Measures for Validation Partition for Regression Tree')\n",
    "regressionSummary(valid_y, bestRegTree.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for new data using Toyota Corolla tree. \n",
    "\n",
    "# Develop dataframe with 2 new records. \n",
    "# Notice that the 'Price' output variable\n",
    "# is not present in these records.\n",
    "new_reg_data = pd.DataFrame({\n",
    "            'Age': [24,34],  \n",
    "            'KM': [35200, 20840],\n",
    "            'HP': [90, 190],  \n",
    "            'Metalic': [0, 0],\n",
    "            'Automatic': [0, 1],\n",
    "            'CC': [0,0],\n",
    "            'Doors': [3, 4],  \n",
    "            'Tax': [85, 220],  \n",
    "            'Weight': [1120, 1000],\n",
    "            'Fuel_Diesel': [1, 0],\n",
    "            'Fuel_Petrol': [0, 1],  \n",
    "})\n",
    "\n",
    "# Make predictions for new Toyota Corolla data using\n",
    "# regression tree and round them to 2 decimals.\n",
    "pred_reg_tree = bestRegTree.predict(new_reg_data)\n",
    "pred_reg_tree = np.round(pred_reg_tree, decimals=2)\n",
    "\n",
    "# Display new data and display 'Price' prediction \n",
    "# for each record.\n",
    "pred_reg_result = pd.DataFrame({\n",
    "            'Age': [24,34],  \n",
    "            'KM': [35200, 20840],\n",
    "            'HP': [90, 190],  \n",
    "            'Metalic': [0, 0],\n",
    "            'Automatic': [0, 1],\n",
    "            'CC': [0,0],\n",
    "            'Doors': [3, 4],  \n",
    "            'Tax': [85, 220],  \n",
    "            'Weight': [1120, 1000],\n",
    "            'Fuel_Diesel': [1, 0],\n",
    "            'Fuel_Petrol': [0, 1],  \n",
    "            'Predicted Price': pred_reg_tree,\n",
    "})\n",
    "\n",
    "print('New Toyota Corolla Data and Predictions for New Data')\n",
    "print(pred_reg_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Random Forest algorithm for Universal Bank personal loans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame for Universal Bank data set.\n",
    "bank_df = pd.read_csv('UniversalBank.csv')\n",
    "\n",
    "# Drop (remove)'ID' and 'ZIP Code' variables which are\n",
    "# not relevant for model building. \n",
    "bank_df = bank_df.drop(columns=['ID', 'ZIP Code'])\n",
    "\n",
    "# Define predictors X (all variabels without 'Personal Loan'),\n",
    "# and outcome variable y ('Personal Loan').\n",
    "X = bank_df.drop(columns=['Personal Loan'])\n",
    "y = bank_df['Personal Loan']\n",
    "\n",
    "# Create data partition with training set, 60%(0.6), and \n",
    "# validation set 40%(0.4) of the ToyotaCorolla data set.\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply RandomForestClassifier() function to develop a combined\n",
    "# (ensemple) classification tree using Random Forest algorithm.\n",
    "rf = RandomForestClassifier(n_estimators=500, random_state=1)\n",
    "rf.fit(train_X, train_y)\n",
    "\n",
    "# Display number of nodes in Random Forest trees.\n",
    "n_nodes = rf.estimators_[0].tree_.node_count\n",
    "print('Number of Nodes in Tree in Random Forest:', n_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for Random Forest classification. \n",
    "\n",
    "# Identify  and display confusion matrix for training partition. \n",
    "print('Training Partition for Random Forests')\n",
    "classificationSummary(train_y, rf.predict(train_X))\n",
    "\n",
    "# Identify  and display confusion matrix for validation partition. \n",
    "print()\n",
    "print('Validation Partition for Random Forests')\n",
    "classificationSummary(valid_y, rf.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Random Forest, identify variable importance scores. \n",
    "importances = rf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf.estimators_], axis=0)\n",
    "\n",
    "# Develop data frame for variable importance. The table data is sorted\n",
    "# in descending order (ascending=False).\n",
    "score_df = pd.DataFrame({'Feature': train_X.columns, 'Importance': importances, 'Std': std})\n",
    "score_df = score_df.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Display variable importance for Random Forest results. \n",
    "print('Variable Importance Scores for Random Forest')\n",
    "print(score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop variable importance plot.\n",
    "score_df = score_df.sort_values('Importance')\n",
    "ax = score_df.plot(kind='barh', x='Feature')\n",
    "ax.set_ylabel('')\n",
    "plt.title('Variable Importance Plot')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Boosted Tree algorithm for Universal Bank personal loans. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply GradientBoostingClassifier() function to develop a combined\n",
    "# boosted tree.  \n",
    "boost = GradientBoostingClassifier(n_estimators=500, random_state=1)\n",
    "boost.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for Boosted Tree classification. \n",
    "\n",
    "# Identify  and show confusion matrix for training partition. \n",
    "print('Training Partition for Boosted Tree')\n",
    "classificationSummary(train_y, boost.predict(train_X))\n",
    "\n",
    "# Identify  and show confusion matrix for validation partition. \n",
    "print()\n",
    "print('Validation Partition for Boosted Tree')\n",
    "classificationSummary(valid_y, boost.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
